import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import warnings
warnings.filterwarnings('ignore')

class RiskScoreCalculator:
    """
    Ã‡ok bileÅŸenli risk skoru hesaplama sistemi
    """
    
    def __init__(self, df, config_file=None):
        """
        Parametreler:
        df: Analiz edilecek DataFrame
        config_file: Risk aÄŸÄ±rlÄ±klarÄ±nÄ± iÃ§eren JSON dosyasÄ± (opsiyonel)
        """
        self.df = df.copy()
        self.risk_weights = self.load_risk_weights(config_file)
        self.user_profiles = {}
        
        # Veriyi hazÄ±rla
        self.prepare_data()
        
    def load_risk_weights(self, config_file):
        """Risk bileÅŸenlerinin aÄŸÄ±rlÄ±klarÄ±nÄ± yÃ¼kle"""
        # VarsayÄ±lan risk komponenti tanÄ±mlarÄ±
        default_risk_components = {
            'time_anomaly': {
                'column_name': 'risk_time_anomaly',
                'weight': 0.19,  # ArtÄ±rÄ±ldÄ± (0.17 â†’ 0.19)
                'description': 'KullanÄ±cÄ±nÄ±n normal giriÅŸ saatlerinden sapma riski'
            },
            'device_change': {
                'column_name': 'risk_device_change', 
                'weight': 0.10,  # AzaltÄ±ldÄ± (0.12 â†’ 0.10)
                'description': 'Browser deÄŸiÅŸim riski'
            },
            'mfa_change': {
                'column_name': 'risk_mfa_change',
                'weight': 0.18,  # ArtÄ±rÄ±ldÄ± (0.16 â†’ 0.18) - En kritik faktÃ¶r
                'description': 'MFA yÃ¶ntemi deÄŸiÅŸim ve gÃ¼venlik seviyesi riski'
            },
            'app_change': {
                'column_name': 'risk_app_change',
                'weight': 0.07,  # AzaltÄ±ldÄ± (0.08 â†’ 0.07)
                'description': 'Uygulama deÄŸiÅŸim riski'
            },
            'ip_change': {
                'column_name': 'risk_ip_change',
                'weight': 0.12,  # ArtÄ±rÄ±ldÄ± (0.10 â†’ 0.12)
                'description': 'IP adresi deÄŸiÅŸim riski'
            },
            'location': {
                'column_name': 'risk_location',
                'weight': 0.09,  # ArtÄ±rÄ±ldÄ± (0.08 â†’ 0.09)
                'description': 'CoÄŸrafi lokasyon riski'
            },
            'session_duration': {
                'column_name': 'risk_session_duration',
                'weight': 0.05,  # ArtÄ±rÄ±ldÄ± (0.04 â†’ 0.05)
                'description': 'Anormal session sÃ¼resi riski'
            },
            'failed_attempts': {
                'column_name': 'risk_failed_attempts',
                'weight': 0.11,  # ArtÄ±rÄ±ldÄ± (0.09 â†’ 0.11)
                'description': 'BaÅŸarÄ±sÄ±z giriÅŸ denemesi riski'
            },
            'combined_temporal': {
                'column_name': 'risk_combined_temporal',
                'weight': 0.04,  # AynÄ±
                'description': 'BirleÅŸik temporal anomali riski'
            },
            'unit_change': {
                'column_name': 'risk_unit_change',
                'weight': 0.03,  # AzaltÄ±ldÄ± (0.07 â†’ 0.03) - DÃ¼ÅŸÃ¼k impact
                'description': 'Departman deÄŸiÅŸim riski'
            },
            'title_change': {
                'column_name': 'risk_title_change',
                'weight': 0.02,  # AzaltÄ±ldÄ± (0.05 â†’ 0.02) - DÃ¼ÅŸÃ¼k impact
                'description': 'Pozisyon deÄŸiÅŸim riski'
            }
        }
        
        if config_file:
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    loaded_config = json.load(f)
                # Config yapÄ±sÄ±na gÃ¶re yÃ¼kleme
                if 'risk_weights' in loaded_config:
                    loaded_weights = loaded_config['risk_weights']
                    
                    # Yeni yapÄ±yÄ± destekle (sadece weight deÄŸerleri)
                    if isinstance(loaded_weights, dict):
                        for component_name, component_data in default_risk_components.items():
                            if component_name in loaded_weights:
                                if isinstance(loaded_weights[component_name], dict):
                                    # Yeni yapÄ±: {'weight': 0.15, 'column_name': '...'}
                                    default_risk_components[component_name].update(loaded_weights[component_name])
                                else:
                                    # Eski yapÄ±: sadece weight deÄŸeri
                                    default_risk_components[component_name]['weight'] = loaded_weights[component_name]
                    
                    print(f"âœ… Risk aÄŸÄ±rlÄ±klarÄ± {config_file} dosyasÄ±ndan yÃ¼klendi.")
                    
                    # YÃ¼klenen aÄŸÄ±rlÄ±klarÄ± gÃ¶ster
                    print("ğŸ“Š YÃ¼klenen Risk AÄŸÄ±rlÄ±klarÄ±:")
                    for name, data in default_risk_components.items():
                        print(f"   {name}: {data['weight']:.3f} ({data['description']})")
                        
                else:
                    print(f"âš ï¸ {config_file} dosyasÄ±nda 'risk_weights' anahtarÄ± bulunamadÄ±.")
                    
            except FileNotFoundError:
                print(f"âš ï¸ {config_file} bulunamadÄ±, varsayÄ±lan aÄŸÄ±rlÄ±klar kullanÄ±lÄ±yor.")
            except Exception as e:
                print(f"âš ï¸ Config yÃ¼kleme hatasÄ±: {e}, varsayÄ±lan aÄŸÄ±rlÄ±klar kullanÄ±lÄ±yor.")
        
        # AÄŸÄ±rlÄ±klarÄ±n toplamÄ±nÄ± kontrol et ve normalize et
        total_weight = sum(comp['weight'] for comp in default_risk_components.values())
        if abs(total_weight - 1.0) > 0.01:
            print(f"âš ï¸ AÄŸÄ±rlÄ±k toplamÄ± {total_weight:.3f}, normalize ediliyor...")
            for component_data in default_risk_components.values():
                component_data['weight'] /= total_weight
        
        # Geriye dÃ¶nÃ¼k uyumluluk iÃ§in basit weight dictionary'si oluÅŸtur
        simple_weights = {name: data['weight'] for name, data in default_risk_components.items()}
        
        # Component mapping'i saklayalÄ±m
        self.risk_components = default_risk_components
        
        return simple_weights
    
    def prepare_data(self):
        """Veriyi risk analizi iÃ§in hazÄ±rla"""
        # Datetime dÃ¶nÃ¼ÅŸÃ¼mÃ¼
        if 'CreatedAt' in self.df.columns:
            self.df['CreatedAt'] = pd.to_datetime(self.df['CreatedAt'])
            self.df['hour'] = self.df['CreatedAt'].dt.hour
            self.df['day_of_week'] = self.df['CreatedAt'].dt.dayofweek
            self.df['is_weekend'] = self.df['day_of_week'] >= 5
        
        # Eksik deÄŸerleri doldur
        # Kolon isimlerini standartlaÅŸtÄ±r
        if 'ClientIP' in self.df.columns and 'IPAddress' not in self.df.columns:
            self.df['IPAddress'] = self.df['ClientIP']
        
        self.df = self.df.fillna({
            'IPAddress': 'unknown',
            'MFAMethod': 'none',
            'CreatedAt':  '00:00:00',
            'Application': 'unknown',
            'Browser': 'unknown',
            'OS': 'unknown',
            'Unit': 'unknown',
            'Title': 'unknown'
        })
        
        print(f"ğŸ“Š Veri hazirlandi: {len(self.df)} kayit")
    
    def create_user_profiles(self):
        """Her kullanici iÃ§in davraniÅŸ profili oluÅŸtur"""
        print("ğŸ‘¤ Kullanici profilleri oluÅŸturuluyor...")
        for user_id in self.df['UserId'].unique():
            user_data = self.df[self.df['UserId'] == user_id].copy()
            
            if len(user_data) > 1:
                # Temporal patterns
                hour_mean = user_data['hour'].mean()
                hour_std = max(user_data['hour'].std(), 1)  # Min 1 saat sapma
                
                # Working patterns
                weekday_logins = user_data[~user_data['is_weekend']]
                weekend_rate = user_data['is_weekend'].mean()
                
                # Device patterns - Browser ve OS ayrÄ± ayrÄ± analiz
                unique_ips = user_data['IPAddress'].nunique()
                unique_browsers = user_data['Browser'].nunique()
                unique_os = user_data['OS'].nunique()
                
                # Browser patterns
                primary_browser = user_data['Browser'].mode().iloc[0] if len(user_data['Browser'].mode()) > 0 else 'unknown'
                browser_diversity = unique_browsers / len(user_data)
                
                # OS patterns  
                primary_os = user_data['OS'].mode().iloc[0] if len(user_data['OS'].mode()) > 0 else 'unknown'
                os_diversity = unique_os / len(user_data)
                
                # Application patterns
                app_diversity = user_data['Application'].nunique()
                primary_app = user_data['Application'].mode().iloc[0] if len(user_data['Application'].mode()) > 0 else 'unknown'
                
                # Unit/Department patterns
                unit_diversity = user_data['Unit'].nunique()
                primary_unit = user_data['Unit'].mode().iloc[0] if len(user_data['Unit'].mode()) > 0 else 'unknown'

                # Title/Position patterns
                title_diversity = user_data['Title'].nunique()
                primary_title = user_data['Title'].mode().iloc[0] if len(user_data['Title'].mode()) > 0 else 'unknown'

                #MFA patterns
                mfa_diversity = user_data['MFAMethod'].nunique()
                primary_mfa = user_data['MFAMethod'].mode().iloc[0] if len(user_data['MFAMethod'].mode()) > 0 else 'unknown'

                self.user_profiles[user_id] = {
                    'hour_mean': hour_mean,
                    'hour_std': hour_std,
                    'weekend_rate': weekend_rate,
                    'ip_diversity': unique_ips / len(user_data),
                    'browser_diversity': browser_diversity,
                    'primary_browser': primary_browser,
                    'os_diversity': os_diversity,
                    'primary_os': primary_os,
                    'app_diversity': app_diversity,
                    'primary_app': primary_app,
                    'unit_diversity': unit_diversity,
                    'primary_unit': primary_unit,
                    'title_diversity': title_diversity,
                    'primary_title': primary_title,
                    'total_logins': len(user_data),
                    'mfa_diversity': mfa_diversity,
                    'primary_mfa': primary_mfa
                }
        
        print(f"âœ… {len(self.user_profiles)} kullanÄ±cÄ± profili oluÅŸturuldu.")
    
    def calculate_time_anomaly_risk(self, row):
        user_id = row['UserId']
        current_hour = row['hour']
        
        if user_id not in self.user_profiles:
            return 0.3  # Yeni kullanÄ±cÄ± iÃ§in orta risk
        
        profile = self.user_profiles[user_id]
        
        # Z-score hesaplama
        z_score = abs(current_hour - profile['hour_mean']) / profile['hour_std']
        
        # 0-1 arasÄ± normalize et (3 sigma = max risk)
        risk = min(z_score / 3.0, 1.0)
        
        return risk
    
    def calculate_device_change_risk(self, row, prev_row):
        user_id = row['UserId']
        current_browser = row['Browser']
        
        if user_id not in self.user_profiles:
            return 0.2  # Yeni kullanÄ±cÄ± iÃ§in dÃ¼ÅŸÃ¼k-orta risk
        
        profile = self.user_profiles[user_id]
        
        # Primary browser'dan farklÄ±ysa risk hesapla
        if current_browser != profile['primary_browser']:
            # Base risk - browser deÄŸiÅŸimi
            base_risk = 0.7
            
            # Diversity factor - kullanÄ±cÄ± Ã§ok browser kullanÄ±yorsa normal
            diversity_factor = min(profile['browser_diversity'], 0.5)  # Max 0.5 azaltma
            
            # Final risk calculation
            risk = max(base_risk - (diversity_factor * 2), 0.1)  # Min 0.1 risk
            return risk
        
        return 0.0  # AynÄ± browser, risk yok

        
    def calculate_os_change_risk(self, row):
        user_id = row['UserId']
        current_os = row['OS']
        
        if user_id not in self.user_profiles:
            return 0.2  # Yeni kullanÄ±cÄ± iÃ§in dÃ¼ÅŸÃ¼k-orta risk
        
        profile = self.user_profiles[user_id]
        
        # Primary OS'ten farklÄ±ysa risk hesapla
        if current_os != profile['primary_os']:
            # Base risk - OS deÄŸiÅŸimi browser'dan daha kritik
            base_risk = 0.8
            
            # Diversity factor - kullanÄ±cÄ± Ã§ok OS kullanÄ±yorsa normal
            diversity_factor = min(profile['os_diversity'], 0.4)  # Max 0.4 azaltma
            
            # Final risk calculation
            risk = max(base_risk - (diversity_factor * 2), 0.2)  # Min 0.2 risk (OS deÄŸiÅŸimi daha kritik)
            return risk
        
        return 0.0  # AynÄ± OS, risk yok
    
    def get_mfa_security_level(self, mfa_method):
        """MFA yÃ¶nteminin gÃ¼venlik seviyesini dÃ¶ndÃ¼r (0-1, yÃ¼ksek deÄŸer = yÃ¼ksek gÃ¼venlik)"""
        mfa_security_levels = {
            # YÃ¼ksek gÃ¼venlik (0.9-1.0)
            'Hardware Token': 1.0,
            'Smart Card': 0.95,
            'Biometric': 0.90,
            
            # Orta-yÃ¼ksek gÃ¼venlik (0.7-0.89)
            'Mobile App (Push)': 0.85,
            'Mobile App (TOTP)': 0.80,
            'Hardware Key (FIDO2)': 0.85,
            
            # Orta gÃ¼venlik (0.5-0.69)
            'SMS': 0.60,
            'Email': 0.50,
            'Voice Call': 0.55,
            
            # DÃ¼ÅŸÃ¼k gÃ¼venlik (0.2-0.49)
            'Security Questions': 0.30,
            'Backup Codes': 0.40,
            
            # GÃ¼venlik yok (0.0-0.19)
            'none': 0.0,
            'disabled': 0.1,
            'unknown': 0.15
        }
        
        return mfa_security_levels.get(mfa_method, 0.15)  # Default: dÃ¼ÅŸÃ¼k gÃ¼venlik
    
    def calculate_mfa_change_risk(self, row, prev_row):
        user_id = row['UserId']
        current_mfa = row['MFAMethod']
        
        if user_id not in self.user_profiles:
            mfa_security = self.get_mfa_security_level(current_mfa)
            return max(1.0 - mfa_security, 0.1)
        
        profile = self.user_profiles[user_id]
        current_security = self.get_mfa_security_level(current_mfa)
        primary_security = self.get_mfa_security_level(profile['primary_mfa'])        
        # 1. MFA DeÄŸiÅŸim Riski
        change_risk = 0.0
        if current_mfa != profile['primary_mfa']:
            base_change_risk = 0.6
            diversity_factor = min(profile['mfa_diversity'] / 5.0, 0.3)
            change_risk = max(base_change_risk - diversity_factor, 0.1)
        # 2. MFA GÃ¼venlik Seviyesi Riski
        security_risk = 1.0 - current_security  # DÃ¼ÅŸÃ¼k gÃ¼venlik = yÃ¼ksek risk
        # 3. GÃ¼venlik Seviyesi DÃ¼ÅŸÃ¼rme Riski (Ã¶nemli!)
        downgrade_risk = 0.0
        if current_security < primary_security:
            # GÃ¼venlik seviyesi dÃ¼ÅŸtÃ¼ - ekstra risk
            downgrade_amount = primary_security - current_security
            downgrade_risk = downgrade_amount * 1.5  # 1.5x Ã§arpan ile cezalandÄ±r
        
        # 4. BirleÅŸik risk hesaplama
        # Change risk: %30, Security risk: %50, Downgrade risk: %20
        combined_risk = (change_risk * 0.3) + (security_risk * 0.5) + (downgrade_risk * 0.2)
        
        return min(combined_risk, 1.0)  # Maksimum 1.0 risk 
    
    def calculate_app_change_risk(self, row):
        user_id = row['UserId']
        current_app = row['Application']

        if user_id not in self.user_profiles:
            return 0.2 
        profile = self.user_profiles[user_id]
        # Primary app'ten farklÄ±ysa risk
        if current_app != profile['primary_app']:
            # App diversity'ye gÃ¶re risk ayarla
            base_risk = 0.7
            diversity_factor = profile['app_diversity'] / 10.0  # Ã‡ok app kullanÄ±yorsa normal
            return max(base_risk - diversity_factor, 0.1)
        
        return 0.0
    
    def calculate_ip_change_risk(self, row, prev_row):
        """IP deÄŸiÅŸim riski (0-1)"""
        if prev_row is None:
            return 0.0
        
        user_id = row['UserId']
        current_ip = row['IPAddress']
        prev_ip = prev_row['IPAddress']
        
        if current_ip != prev_ip:
            # KullanÄ±cÄ±nÄ±n IP diversity'sine gÃ¶re risk ayarla
            if user_id in self.user_profiles:
                diversity = self.user_profiles[user_id]['ip_diversity']
                # Ã‡ok IP kullanÄ±yorsa dÃ¼ÅŸÃ¼k risk
                return max(0.8 - diversity, 0.2)
            return 0.8
        
        return 0.0
    
    def calculate_location_risk(self, row):
        """Lokasyon riski (0-1) - IP bazlÄ± tahmin"""
        # Basit IP-based location risk
        # GerÃ§ek uygulamada GeoIP kullanÄ±labilir
        ip = row['IPAddress']
        
        # IP pattern analizi (basit yaklaÅŸÄ±m)
        if ip.startswith('192.168') or ip.startswith('10.'):
            return 0.1  # Internal IP - dÃ¼ÅŸÃ¼k risk
        elif ip.startswith('172.'):
            return 0.2  # Semi-internal
        else:
            return 0.5  # External IP - orta risk
    
    def calculate_session_duration_risk(self, row):
        """Session sÃ¼re riski (0-1)"""
        # Mock implementation - gerÃ§ek uygulamada session data gerekli
        # Rastgele ama mantÄ±klÄ± deÄŸerler
        np.random.seed(hash(row['UserId']) % 1000)
        
        # Normal session: 30-240 dakika
        normal_min, normal_max = 30, 240
        
        # Simulated session duration
        session_duration = np.random.lognormal(mean=4, sigma=1)  # Log-normal daÄŸÄ±lÄ±m
        
        if session_duration < 5:  # Ã‡ok kÄ±sa session
            return 0.8
        elif session_duration > 480:  # Ã‡ok uzun session (8+ saat)
            return 0.6
        elif session_duration < normal_min:
            return 0.4
        elif session_duration > normal_max:
            return 0.3
        else:
            return 0.1
    
    def calculate_failed_attempts_risk(self, row):
        """BaÅŸarÄ±sÄ±z deneme riski (0-1)"""
        # Mock implementation - gerÃ§ek uygulamada failed attempt data gerekli
        user_id = row['UserId']
        
        # Simulated failed attempts (hash-based deterministic)
        np.random.seed(hash(f"{user_id}_{row['CreatedAt']}") % 1000)
        failed_attempts = np.random.poisson(lam=0.2)  # Ortalama 0.2 failed attempt
        
        if failed_attempts == 0:
            return 0.0
        elif failed_attempts <= 2:
            return 0.3
        elif failed_attempts <= 5:
            return 0.7
        else:
            return 1.0
    
    def calculate_combined_temporal_risk(self, row):
       
        # Zaman + hafta sonu kombinasyonu
        time_risk = self.calculate_time_anomaly_risk(row)
        weekend_risk = 0.3 if row['is_weekend'] else 0.0
        
        # Off-hours risk
        hour = row['hour']
        if hour < 6 or hour > 22:
            offhours_risk = 0.8
        elif hour < 8 or hour > 18:
            offhours_risk = 0.4
        else:
            offhours_risk = 0.0
        
        # AÄŸÄ±rlÄ±klÄ± kombinasyon
        combined = time_risk * 0.5 + weekend_risk * 0.25 + offhours_risk * 0.25
        
        return min(combined, 1.0)
    
    def calculate_unit_change_risk(self, row):
        """Departman deÄŸiÅŸim riski (0-1)"""
        user_id = row['UserId']
        current_unit = row['Unit']
        
        if user_id not in self.user_profiles:
            return 0.1  # Yeni kullanÄ±cÄ± iÃ§in dÃ¼ÅŸÃ¼k risk
        
        profile = self.user_profiles[user_id]
        
        # Primary unit'ten farklÄ±ysa risk
        if current_unit != profile['primary_unit']:
            # Unit diversity'ye gÃ¶re risk ayarla
            base_risk = 0.6  # Departman deÄŸiÅŸimi orta risk
            diversity_factor = profile['unit_diversity'] / 5.0  # Ã‡ok departman kullanÄ±yorsa normal
            return max(base_risk - diversity_factor, 0.1)
        
        return 0.0
    
    def calculate_title_change_risk(self, row):
        """Pozisyon deÄŸiÅŸim riski (0-1)"""
        user_id = row['UserId']
        current_title = row['Title']
        
        if user_id not in self.user_profiles:
            return 0.2  # Yeni kullanÄ±cÄ± iÃ§in dÃ¼ÅŸÃ¼k-orta risk
        
        profile = self.user_profiles[user_id]
        
        # Primary title'dan farklÄ±ysa risk
        if current_title != profile['primary_title']:
            # Title diversity'ye gÃ¶re risk ayarla
            base_risk = 0.8  # Pozisyon deÄŸiÅŸimi yÃ¼ksek risk
            diversity_factor = profile['title_diversity'] / 3.0  # Ã‡ok pozisyon kullanÄ±yorsa normal
            return max(base_risk - diversity_factor, 0.2)
        
        return 0.0
    
    def calculate_risk_scores(self):
        """TÃ¼m risk skorlarÄ±nÄ± hesapla"""
        print("âš–ï¸ Risk skorlarÄ± hesaplanÄ±yor...")
        
        # Ã–nce kullanÄ±cÄ± profillerini oluÅŸtur
        self.create_user_profiles()
        
        # Risk bileÅŸenlerini hesapla
        self.df = self.df.sort_values(['UserId', 'CreatedAt']).reset_index(drop=True)
        
        risk_components = []
        
        for idx, row in self.df.iterrows():
            user_id = row['UserId']
            
            # Ã–nceki kaydÄ± bul (aynÄ± kullanÄ±cÄ±nÄ±n)
            prev_row = None
            if idx > 0 and self.df.iloc[idx-1]['UserId'] == user_id:
                prev_row = self.df.iloc[idx-1]
            
            # Risk bileÅŸenlerini hesapla
            components = {
                'risk_time_anomaly': self.calculate_time_anomaly_risk(row),
                'risk_device_change': self.calculate_device_change_risk(row, prev_row),
                'risk_mfa_change': self.calculate_mfa_change_risk(row, prev_row),
                'risk_app_change': self.calculate_app_change_risk(row),
                'risk_ip_change': self.calculate_ip_change_risk(row, prev_row),
                'risk_location': self.calculate_location_risk(row),
                'risk_session_duration': self.calculate_session_duration_risk(row),
                'risk_failed_attempts': self.calculate_failed_attempts_risk(row),
                'risk_combined_temporal': self.calculate_combined_temporal_risk(row),
                'risk_unit_change': self.calculate_unit_change_risk(row),
                'risk_title_change': self.calculate_title_change_risk(row)
            }
            
            risk_components.append(components)
        
        # DataFrame'e ekle
        risk_df = pd.DataFrame(risk_components)
        self.df = pd.concat([self.df, risk_df], axis=1)
        
        print("âœ… Risk bileÅŸenleri hesaplandÄ±.")
    
    def calculate_final_risk_score(self):
        """Final risk skorunu hesapla (0-100 skala)"""
        print("ğŸ¯ Final risk skoru hesaplanÄ±yor...")
        
        # AÄŸÄ±rlÄ±klÄ± risk skoru
        weighted_risk = 0
        
        # Yeni yapÄ± kullanarak mapping oluÅŸtur
        if hasattr(self, 'risk_components'):
            risk_mapping = {
                data['column_name']: data['weight'] 
                for name, data in self.risk_components.items()
            }
        else:
            # Fallback - eski yapÄ±
            risk_mapping = {
                'risk_time_anomaly': self.risk_weights.get('time_anomaly', 0.18),
                'risk_device_change': self.risk_weights.get('device_change', 0.13),
                'risk_mfa_change': self.risk_weights.get('mfa_change', 0.13),
                'risk_app_change': self.risk_weights.get('app_change', 0.09),
                'risk_ip_change': self.risk_weights.get('ip_change', 0.09),
                'risk_location': self.risk_weights.get('location', 0.09),
                'risk_session_duration': self.risk_weights.get('session_duration', 0.04),
                'risk_failed_attempts': self.risk_weights.get('failed_attempts', 0.09),
                'risk_combined_temporal': self.risk_weights.get('combined_temporal', 0.04),
                'risk_unit_change': self.risk_weights.get('unit_change', 0.08),
                'risk_title_change': self.risk_weights.get('title_change', 0.07)
            }
        
        # Risk skorlarÄ±nÄ± hesapla
        print("ğŸ“Š Risk BileÅŸenleri ve AÄŸÄ±rlÄ±klarÄ±:")
        for risk_col, weight in risk_mapping.items():
            if risk_col in self.df.columns:
                component_risk = self.df[risk_col] * weight
                weighted_risk += component_risk
                
                # Ortalama risk deÄŸerini gÃ¶ster
                avg_risk = self.df[risk_col].mean()
                print(f"   {risk_col}: aÄŸÄ±rlÄ±k={weight:.3f}, ort_risk={avg_risk:.3f}")
            else:
                print(f"   âš ï¸ {risk_col} kolonu bulunamadÄ±!")
        
        # 0-100 skalaya Ã§evir (yÃ¼ksek skor = dÃ¼ÅŸÃ¼k risk)
        self.df['RiskScore'] = (1 - weighted_risk) * 100
        
        # 0-100 arasÄ±nda sÄ±nÄ±rla
        self.df['RiskScore'] = self.df['RiskScore'].clip(0, 100)
        
        print("âœ… Final risk skoru hesaplandÄ±.")
        
        # Ä°statistikler
        print(f"ğŸ“Š Risk Skoru Ä°statistikleri:")
        print(f"   Ortalama: {self.df['RiskScore'].mean():.1f}")
        print(f"   Medyan: {self.df['RiskScore'].median():.1f}")
        print(f"   Min: {self.df['RiskScore'].min():.1f}")
        print(f"   Max: {self.df['RiskScore'].max():.1f}")
        print(f"   Std: {self.df['RiskScore'].std():.1f}")
    
    def export_risk_analysis(self, filename=None):
        """Risk analiz sonuÃ§larÄ±nÄ± export et"""
        if filename is None:
            filename = f"risk_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        self.df.to_csv(filename, index=False, sep=';')
        print(f"\nâœ… Risk analizi {filename} dosyasÄ±na kaydedildi.")
        
        return filename
    
    def save_risk_weights(self, filename=None):
        """Risk aÄŸÄ±rlÄ±klarÄ±nÄ± kaydet"""
        if filename is None:
            filename = f"risk_weights_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # Yeni yapÄ±da kaydet
        config_data = {
            "risk_components": self.risk_components if hasattr(self, 'risk_components') else {},
            "risk_weights": self.risk_weights,
            "saved_date": datetime.now().isoformat(),
            "description": "Risk bileÅŸenleri ve aÄŸÄ±rlÄ±klarÄ± - kolon adlarÄ± ile birlikte"
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Risk aÄŸÄ±rlÄ±klarÄ± {filename} dosyasÄ±na kaydedildi.")
        print("ğŸ“‹ Kaydedilen yapÄ±:")
        
        if hasattr(self, 'risk_components'):
            for name, data in self.risk_components.items():
                print(f"   {name}: {data['weight']:.3f} -> {data['column_name']}")
        
        return filename
    
    def get_top_risk_factors(self, top_n=5):
        """En yÃ¼ksek risk faktÃ¶rlerini gÃ¶ster"""
        print(f"\nğŸ” TOP {top_n} RÄ°SK FAKTÃ–RÃœ:")
        print("-" * 30)
        
        # Risk bileÅŸenlerinin ortalama deÄŸerlerini hesapla
        risk_columns = [col for col in self.df.columns if col.startswith('risk_')]
        
        risk_averages = []
        for col in risk_columns:
            avg_risk = self.df[col].mean()
            weight = 0.1  # Default weight
            
            # AÄŸÄ±rlÄ±ÄŸÄ± bul
            if hasattr(self, 'risk_components'):
                for name, data in self.risk_components.items():
                    if data['column_name'] == col:
                        weight = data['weight']
                        break
            
            impact = avg_risk * weight
            risk_averages.append({
                'component': col,
                'avg_risk': avg_risk,
                'weight': weight,
                'impact': impact
            })
        
        # Impact'e gÃ¶re sÄ±rala
        risk_averages.sort(key=lambda x: x['impact'], reverse=True)
        
        # Top N'i gÃ¶ster
        for i, risk in enumerate(risk_averages[:top_n], 1):
            print(f"   {i}. {risk['component']}: impact={risk['impact']:.3f} (risk={risk['avg_risk']:.3f}, weight={risk['weight']:.3f})")

    def run_full_analysis(self):
        """Tam risk analizi pipeline'Ä±"""
        print("ğŸ”„ TAM RÄ°SK ANALÄ°ZÄ° BAÅLIYOR")
        print("="*50)
        
        # 1. Risk skorlarÄ±nÄ± hesapla
        self.calculate_risk_scores()
        
        # 2. Final skoru hesapla
        self.calculate_final_risk_score()
        
        # 3. Top risk faktÃ¶rleri gÃ¶ster
        self.get_top_risk_factors()
        
        print(f"\nğŸ‰ Risk analizi tamamlandÄ±!")
        return self.df
